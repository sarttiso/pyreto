import numpy as np


class FitPareto:
    def __init__(self, X):
        self.X = X
        self.n = len(X)
        self.Y = np.log(np.min(X))
        self.Z = np.log(np.max(X))
        self.T = np.sum(np.log(X))
        self.jstar = np.floor((self.T-self.n*self.Y)/(self.Z-self.Y))

    def nu(self, method='Beg'):
        if method=='Beg':
            return np.max(self.X) * ( 1 + (self.T-self.n*self.Y)/(self.n*(self.n-1)) *\
                                      ((1 - self.Sj_num_nu(1))/(self.Lj(1)**(self.n-3) - self.Sj_den(2))) )
        elif method=='Aban':
            return np.max(self.X)

    def alpha(self, method='Beg'):
        if method=='Beg':
             return (self.n-3)/(self.T-self.n*self.Y) * (self.Lj(1)**(self.n-4) - self.Sj_num(2))/(self.Lj(1)**(self.n-3) - self.Sj_den(2))
        elif method=='Aban':
            return

    def aban_solve_alpha(self, alpha):  
        return
    
    # use recursive solutions from Maschberger and Beg
    def Sj_num(self, j):
        # base case
        if j == self.jstar:
            return 0
        # otherwise
        else:
            return (self.n-j)/(j-1) * (self.Lj(j)**(self.n-4) - self.Sj_num(j+1))

    def Sj_den(self, j):
        # base case
        if j == self.jstar:
            return 0
        # otherwise
        else:
            return (self.n-j)/(j-1) * (self.Lj(j)**(self.n-3) - self.Sj_den(j+1))
        
    def Sj_num_nu(self, j):
        # base case
        if j == self.jstar:
            return 0
        # otherwise
        else:
            return (self.n-j)/j * (self.Lj(j)**(self.n-2) - self.Sj_num_nu(j+1))

    def Lj(self, j):
        return 1-j*(self.Z-self.Y)/(self.T-self.n*self.Y)


def fit_nu_Beg(X):
    """
    given samples X assumed to be generated by a truncated Pareto distribution, fit the truncation parameter for the distribution.
    X is a vector.
    Implementation of Maschberger and Kroupa (2009) for approach of Beg (1983)
    """
    n = len(X)
    Y = np.log(np.min(X))
    Z = np.log(np.max(X))
    T = np.sum(np.log(X))
    jstar = np.floor((T-n*Y)/(Z-Y))

    def Sj_num(j):
        # base case
        if j == jstar:
            return 0
        # otherwise
        else:
            return (n-j)/(j-1) * (Lj(j)**(n-4) - Sj_num(j+1))
        
    def Sj_den(j):
        # base case
        if j == jstar:
            return 0
        # otherwise
        else:
            return (n-j)/(j-1) * (Lj(j)**(n-3) - Sj_den(j+1))

    def Sj_num_nu(j):
        # base case
        if j == jstar:
            return 0
        # otherwise
        else:
            return (n-j)/j * (Lj(j)**(n-2) - Sj_num_nu(j+1))

    def Lj(j):
        return 1-j*(Z-Y)/(T-n*Y)

    return np.max(X) * ( 1 + (T-n*Y)/(n*(n-1)) * ((1 - Sj_num_nu(1))/(Lj(1)**(n-3) - Sj_den(2))) )


# def fit_alpha_beg(X):
#     n = len(X)
#     Y = np.log(np.min(X))
#     Z = np.log(np.max(X))
#     T = np.sum(np.log(X))
#     jstar = np.floor((T-n*Y)/(Z-Y))

def pareto_trunc_pdf(x, gamma, alpha, nu):
    """_summary_

    Args:
        x (_type_): _description_
        gamma (_type_): _description_
        alpha (_type_): _description_
        nu (_type_): _description_

    Returns:
        _type_: _description_
    """
    p = (alpha*gamma**alpha*x**(-alpha-1))/(1-(gamma/nu)**alpha)
    return p


def pareto_trunc_cdf(x, gamma, alpha, nu):
    """_summary_

    Args:
        x (_type_): _description_
        gamma (_type_): _description_
        alpha (_type_): _description_
        nu (_type_): _description_

    Returns:
        _type_: _description_
    """
    P = 1 - (gamma**alpha * (x**(-alpha) - nu**(-alpha))) / (1 - (gamma/nu)**alpha)
    P[x < gamma] = 0
    return P

# inverse transform stampling
def pareto_trunc_sample(n, gamma, alpha, nu):
    """_summary_

    Args:
        n (_type_): _description_
        gamma (_type_): _description_
        alpha (_type_): _description_
        nu (_type_): _description_

    Returns:
        _type_: _description_
    """
    x = np.logspace(np.log10(gamma), np.log10(nu), 1000)
    # get CDF
    P = pareto_trunc_cdf(x, gamma, alpha, nu)
    # uniform random 
    r = np.random.uniform(size=int(n))
    # transform to truncated pareto
    samp = np.interp(r, P, x)
    return samp