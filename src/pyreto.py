import numpy as np
from scipy.optimize import root_scalar, root


class FitParetoTrunc:
    def __init__(self, X):
        """
        given samples X assumed to be generated by a truncated Pareto distribution, fit the truncation parameter for the distribution.
        X is a vector.
        Implementation of Maschberger and Kroupa (2009) for approach of Beg (1983)
        """
        # sort descending order
        self.X = np.sort(X)[::-1]
        self.n = len(X)
        self.Y = np.log(np.min(X))
        self.Z = np.log(np.max(X))
        self.T = np.sum(np.log(X))
        self.jstar = np.floor((self.T-self.n*self.Y)/(self.Z-self.Y))

    def nu(self, method='Beg'):
        if method=='Beg':
            return np.max(self.X) * ( 1 + (self.T-self.n*self.Y)/(self.n*(self.n-1)) *\
                                      ((1 - self.Sj_num_nu(1))/(self.Lj(1)**(self.n-3) - self.Sj_den(2))) )
        elif method=='Aban':
            return np.max(self.X)

    def alpha(self, method='Beg', r=None):
        """Fit the power law exponent.

        Args:
            method (str, optional): Method to use. Options are Beg and Aban. Defaults to 'Beg'.
            r (int, optional): Whether to fit a tail if using the Aban method. Defaults to 0.

        Returns:
            alpha (float): power law exponent
        """
        if method=='Beg':
             return (self.n-3)/(self.T-self.n*self.Y) * (self.Lj(1)**(self.n-4) - self.Sj_num(2))/(self.Lj(1)**(self.n-3) - self.Sj_den(2))
        elif method=='Aban':
            cur_alpha = root_scalar(self.aban_solve_alpha, args=(r), bracket=[-100, 100]).root
            return cur_alpha

    def aban_solve_alpha(self, alpha, r=None):
        # no r, then using eqn 5 from Adan
        if r is None:
            r = self.n
            r_idx = self.n - 1
        else:
            r = int(r)
            r_idx = r

        to_minimize = r/alpha + \
              (r*(self.X[r_idx]/self.X[0])**alpha * np.log(self.X[r_idx]/self.X[0])) / (1 - (self.X[r_idx]/self.X[0])**alpha) - \
              np.sum(np.log(self.X[0:r_idx+1]) - np.log(self.X[r_idx]))

        return to_minimize
    
    # use recursive solutions from Maschberger and Beg
    def Sj_num(self, j):
        # base case
        if j == self.jstar:
            return 0
        # otherwise
        else:
            return (self.n-j)/(j-1) * (self.Lj(j)**(self.n-4) - self.Sj_num(j+1))

    def Sj_den(self, j):
        # base case
        if j == self.jstar:
            return 0
        # otherwise
        else:
            return (self.n-j)/(j-1) * (self.Lj(j)**(self.n-3) - self.Sj_den(j+1))
        
    def Sj_num_nu(self, j):
        # base case
        if j == self.jstar:
            return 0
        # otherwise
        else:
            return (self.n-j)/j * (self.Lj(j)**(self.n-2) - self.Sj_num_nu(j+1))

    def Lj(self, j):
        return 1-j*(self.Z-self.Y)/(self.T-self.n*self.Y)
    

class FitParetoTemp:
    def __init__(self, X):
        # sort descending order
        self.X = np.sort(X)[::-1]
        self.n = len(X)

    def fit(self, dx):

        cur_X = self.X[self.X > dx]

        k = len(cur_X)


        sol = root(self.meerschaert_eqns, [0.5, 1], args=(dx, cur_X))
        alpha = sol.x[0]
        beta = sol.x[1]
        # Meerschaert et al. 2012 2.6
        gamma = k/self.n * dx**alpha * np.exp(beta*dx)

        return alpha, beta, gamma
    
    def meerschaert_eqns(self, m, dx, X):
        """Meerschaert et al. 2012 2.4-2.5
        m[0] alpha
        m[1] beta

        X is prefiltered for dx
        """
        f = [np.sum(np.log(dx) - np.log(X)) + np.sum(1/(m[0] + m[1]*X)),
             np.sum(dx - X) + np.sum(X/(m[0] + m[1]*X))]
        return f


def pareto_trunc_pdf(x, gamma, alpha, nu):
    """_summary_

    Args:
        x (_type_): _description_
        gamma (_type_): _description_
        alpha (_type_): _description_
        nu (_type_): _description_

    Returns:
        _type_: _description_
    """
    p = (alpha*gamma**alpha*x**(-alpha-1))/(1-(gamma/nu)**alpha)
    return p


def pareto_trunc_cdf(x, gamma, alpha, nu):
    """_summary_

    Args:
        x (_type_): _description_
        gamma (_type_): _description_
        alpha (_type_): _description_
        nu (_type_): _description_

    Returns:
        _type_: _description_
    """
    P = 1 - (gamma**alpha * (x**(-alpha) - nu**(-alpha))) / (1 - (gamma/nu)**alpha)
    P[x < gamma] = 0
    return P

# inverse transform stampling
def pareto_trunc_sample(n, gamma, alpha, nu):
    """_summary_

    Args:
        n (_type_): _description_
        gamma (_type_): _description_
        alpha (_type_): _description_
        nu (_type_): _description_

    Returns:
        _type_: _description_
    """
    x = np.logspace(np.log10(gamma), np.log10(nu), 1000)
    # get CDF
    P = pareto_trunc_cdf(x, gamma, alpha, nu)
    # uniform random 
    r = np.random.uniform(size=int(n))
    # transform to truncated pareto
    samp = np.interp(r, P, x)
    return samp